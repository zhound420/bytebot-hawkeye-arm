# Hawkeye Precision Features
BYTEBOT_GRID_OVERLAY=true
BYTEBOT_GRID_DEBUG=false
BYTEBOT_PROGRESSIVE_ZOOM_USE_AI=true
BYTEBOT_SMART_FOCUS=true
BYTEBOT_SMART_FOCUS_MODEL=gpt-4o-mini
BYTEBOT_UNIVERSAL_TEACHING=true
BYTEBOT_ADAPTIVE_CALIBRATION=true
BYTEBOT_ZOOM_REFINEMENT=true
BYTEBOT_COORDINATE_METRICS=true
BYTEBOT_COORDINATE_DEBUG=false

# Click Accuracy Settings
BYTEBOT_SMART_CLICK_SUCCESS_RADIUS=12
BYTEBOT_POST_CLICK_CALIBRATION=true
BYTEBOT_DRIFT_COMPENSATION=true
BYTEBOT_DRIFT_SMOOTHING=0.2
BYTEBOT_PRECLICK_SNAP=true
BYTEBOT_SNAP_RADIUS=6
BYTEBOT_SNAP_PENALTY=0.25
BYTEBOT_CLICK_RETRY_ON_NOCHANGE=true
BYTEBOT_CLICK_VERIFY_DELAY=250
BYTEBOT_CLICK_VERIFY_RADIUS=12
BYTEBOT_CLICK_VERIFY_THRESHOLD=4.0
BYTEBOT_CLICK_RETRY_MAX=1

# ==============================================================================
# OmniParser Integration (Microsoft OmniParser v2.0)
# ==============================================================================
# Note: OMNIPARSER_URL is platform-specific - set automatically by scripts
# - Apple Silicon: http://host.docker.internal:9989 (native with MPS GPU)
# - x86_64: http://bytebot-omniparser:9989 (Docker container)
BYTEBOT_CV_USE_OMNIPARSER=true
OMNIPARSER_URL=http://bytebot-omniparser:9989
OMNIPARSER_TIMEOUT=30000

# Performance profile: SPEED (2-3s), BALANCED (4-6s), or QUALITY (10-16s)
# SPEED: Disables OCR, limits captions to 15, uses simple prompts
# BALANCED: Selective OCR, limits captions to 25, detailed prompts (RECOMMENDED)
# QUALITY: Full OCR, up to 100 captions, maximum accuracy
OMNIPARSER_PERFORMANCE_PROFILE=BALANCED

# Advanced settings (override profile defaults if needed)
# OMNIPARSER_ENABLE_OCR=true              # Enable OCR text detection (auto-determined by profile)
# OMNIPARSER_MAX_CAPTIONS=25              # Maximum elements to caption (auto-determined by profile)
# OMNIPARSER_CAPTION_PROMPT=DETAILED_CAPTION  # Caption detail level (auto-determined by profile)
# OMNIPARSER_BATCH_SIZE=32                # Caption batch size for MPS (32) or GPU (128)
# OMNIPARSER_MIN_CONFIDENCE=0.05          # Minimum confidence threshold
# OMNIPARSER_IOU_THRESHOLD=0.1            # Overlap removal threshold

# Device configuration (auto-detect recommended)
OMNIPARSER_DEVICE=auto
OMNIPARSER_MODEL_DTYPE=float16

# ==============================================================================
# Desktop Platform Selection
# ==============================================================================
# Choose desktop environment: 'linux' (default) or 'windows'
BYTEBOT_DESKTOP_PLATFORM=linux

# Desktop service URLs (configured automatically based on platform)
BYTEBOT_DESKTOP_LINUX_URL=http://bytebot-desktop:9990
BYTEBOT_DESKTOP_WINDOWS_URL=http://omnibox-adapter:5001

# ==============================================================================
# OmniBox Configuration (Windows 11 VM)
# ==============================================================================
# Note: OmniBox is optional and uses docker-compose profile 'omnibox'
# Start with: docker compose --profile omnibox up -d

# VM Resources
OMNIBOX_RAM_SIZE=8G
OMNIBOX_CPU_CORES=4
OMNIBOX_DISK_SIZE=64G

# OmniBox API timeout
OMNIBOX_TIMEOUT=30000

# ==============================================================================
# LMStudio Local Model Server
# ==============================================================================
# LMStudio IP address and port
# Run ./scripts/setup-lmstudio.sh to auto-discover VLM models
LMSTUDIO_URL=http://192.168.4.112:1234

# Auto-discovery will:
# - Connect to LMStudio API
# - Find all Vision Language Models (VLMs)
# - Configure them in litellm-config.yaml
# - Make them available in the UI model picker
#
# VLMs are detected by model name patterns:
# - Contains: vl, vision, visual, multimodal
# - Known families: llava, qwen-vl, cogvlm, internvl, ui-tars
